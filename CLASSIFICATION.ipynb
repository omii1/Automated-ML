{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a399f7a",
   "metadata": {},
   "source": [
    "# Importing the Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "038a9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8f6d8225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            2      138             62             35        0  33.6   \n",
       "1            0       84             82             31      125  38.2   \n",
       "2            0      145              0              0        0  44.2   \n",
       "3            0      135             68             42      250  42.3   \n",
       "4            1      139             62             41      480  40.7   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.127   47        1  \n",
       "1                     0.233   23        0  \n",
       "2                     0.630   31        1  \n",
       "3                     0.365   24        1  \n",
       "4                     0.536   21        0  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"E:\\Ineuron Internship\\Automated ML\\AutoML\\Datasets\\diabetes-dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1b91aff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin    BMI  \\\n",
       "0           False    False          False          False    False  False   \n",
       "1           False    False          False          False    False  False   \n",
       "2           False    False          False          False    False  False   \n",
       "3           False    False          False          False    False  False   \n",
       "4           False    False          False          False    False  False   \n",
       "...           ...      ...            ...            ...      ...    ...   \n",
       "1995        False    False          False          False    False  False   \n",
       "1996        False    False          False          False    False  False   \n",
       "1997        False    False          False          False    False  False   \n",
       "1998        False    False          False          False    False  False   \n",
       "1999        False    False          False          False    False  False   \n",
       "\n",
       "      DiabetesPedigreeFunction    Age  Outcome  \n",
       "0                        False  False    False  \n",
       "1                        False  False    False  \n",
       "2                        False  False    False  \n",
       "3                        False  False    False  \n",
       "4                        False  False    False  \n",
       "...                        ...    ...      ...  \n",
       "1995                     False  False    False  \n",
       "1996                     False  False    False  \n",
       "1997                     False  False    False  \n",
       "1998                     False  False    False  \n",
       "1999                     False  False    False  \n",
       "\n",
       "[2000 rows x 9 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "38cada25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3818d3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               2000 non-null   int64  \n",
      " 1   Glucose                   2000 non-null   int64  \n",
      " 2   BloodPressure             2000 non-null   int64  \n",
      " 3   SkinThickness             2000 non-null   int64  \n",
      " 4   Insulin                   2000 non-null   int64  \n",
      " 5   BMI                       2000 non-null   float64\n",
      " 6   DiabetesPedigreeFunction  2000 non-null   float64\n",
      " 7   Age                       2000 non-null   int64  \n",
      " 8   Outcome                   2000 non-null   int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 140.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5669eb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.703500</td>\n",
       "      <td>121.182500</td>\n",
       "      <td>69.145500</td>\n",
       "      <td>20.935000</td>\n",
       "      <td>80.254000</td>\n",
       "      <td>32.193000</td>\n",
       "      <td>0.470930</td>\n",
       "      <td>33.090500</td>\n",
       "      <td>0.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.306063</td>\n",
       "      <td>32.068636</td>\n",
       "      <td>19.188315</td>\n",
       "      <td>16.103243</td>\n",
       "      <td>111.180534</td>\n",
       "      <td>8.149901</td>\n",
       "      <td>0.323553</td>\n",
       "      <td>11.786423</td>\n",
       "      <td>0.474498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>63.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.375000</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>744.000000</td>\n",
       "      <td>80.600000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies      Glucose  BloodPressure  SkinThickness      Insulin  \\\n",
       "count  2000.000000  2000.000000    2000.000000    2000.000000  2000.000000   \n",
       "mean      3.703500   121.182500      69.145500      20.935000    80.254000   \n",
       "std       3.306063    32.068636      19.188315      16.103243   111.180534   \n",
       "min       0.000000     0.000000       0.000000       0.000000     0.000000   \n",
       "25%       1.000000    99.000000      63.500000       0.000000     0.000000   \n",
       "50%       3.000000   117.000000      72.000000      23.000000    40.000000   \n",
       "75%       6.000000   141.000000      80.000000      32.000000   130.000000   \n",
       "max      17.000000   199.000000     122.000000     110.000000   744.000000   \n",
       "\n",
       "               BMI  DiabetesPedigreeFunction          Age      Outcome  \n",
       "count  2000.000000               2000.000000  2000.000000  2000.000000  \n",
       "mean     32.193000                  0.470930    33.090500     0.342000  \n",
       "std       8.149901                  0.323553    11.786423     0.474498  \n",
       "min       0.000000                  0.078000    21.000000     0.000000  \n",
       "25%      27.375000                  0.244000    24.000000     0.000000  \n",
       "50%      32.300000                  0.376000    29.000000     0.000000  \n",
       "75%      36.800000                  0.624000    40.000000     1.000000  \n",
       "max      80.600000                  2.420000    81.000000     1.000000  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e0a42506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.120405</td>\n",
       "      <td>0.149672</td>\n",
       "      <td>-0.063375</td>\n",
       "      <td>-0.076600</td>\n",
       "      <td>0.019475</td>\n",
       "      <td>-0.025453</td>\n",
       "      <td>0.539457</td>\n",
       "      <td>0.224437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.120405</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138044</td>\n",
       "      <td>0.062368</td>\n",
       "      <td>0.320371</td>\n",
       "      <td>0.226864</td>\n",
       "      <td>0.123243</td>\n",
       "      <td>0.254496</td>\n",
       "      <td>0.458421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.149672</td>\n",
       "      <td>0.138044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>0.087384</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.051331</td>\n",
       "      <td>0.238375</td>\n",
       "      <td>0.075958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>-0.063375</td>\n",
       "      <td>0.062368</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448859</td>\n",
       "      <td>0.393760</td>\n",
       "      <td>0.178299</td>\n",
       "      <td>-0.111034</td>\n",
       "      <td>0.076040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>-0.076600</td>\n",
       "      <td>0.320371</td>\n",
       "      <td>0.087384</td>\n",
       "      <td>0.448859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.223012</td>\n",
       "      <td>0.192719</td>\n",
       "      <td>-0.085879</td>\n",
       "      <td>0.120924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.019475</td>\n",
       "      <td>0.226864</td>\n",
       "      <td>0.281545</td>\n",
       "      <td>0.393760</td>\n",
       "      <td>0.223012</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.125719</td>\n",
       "      <td>0.038987</td>\n",
       "      <td>0.276726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>-0.025453</td>\n",
       "      <td>0.123243</td>\n",
       "      <td>0.051331</td>\n",
       "      <td>0.178299</td>\n",
       "      <td>0.192719</td>\n",
       "      <td>0.125719</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026569</td>\n",
       "      <td>0.155459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.539457</td>\n",
       "      <td>0.254496</td>\n",
       "      <td>0.238375</td>\n",
       "      <td>-0.111034</td>\n",
       "      <td>-0.085879</td>\n",
       "      <td>0.038987</td>\n",
       "      <td>0.026569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>0.224437</td>\n",
       "      <td>0.458421</td>\n",
       "      <td>0.075958</td>\n",
       "      <td>0.076040</td>\n",
       "      <td>0.120924</td>\n",
       "      <td>0.276726</td>\n",
       "      <td>0.155459</td>\n",
       "      <td>0.236509</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Pregnancies   Glucose  BloodPressure  SkinThickness  \\\n",
       "Pregnancies                  1.000000  0.120405       0.149672      -0.063375   \n",
       "Glucose                      0.120405  1.000000       0.138044       0.062368   \n",
       "BloodPressure                0.149672  0.138044       1.000000       0.198800   \n",
       "SkinThickness               -0.063375  0.062368       0.198800       1.000000   \n",
       "Insulin                     -0.076600  0.320371       0.087384       0.448859   \n",
       "BMI                          0.019475  0.226864       0.281545       0.393760   \n",
       "DiabetesPedigreeFunction    -0.025453  0.123243       0.051331       0.178299   \n",
       "Age                          0.539457  0.254496       0.238375      -0.111034   \n",
       "Outcome                      0.224437  0.458421       0.075958       0.076040   \n",
       "\n",
       "                           Insulin       BMI  DiabetesPedigreeFunction  \\\n",
       "Pregnancies              -0.076600  0.019475                 -0.025453   \n",
       "Glucose                   0.320371  0.226864                  0.123243   \n",
       "BloodPressure             0.087384  0.281545                  0.051331   \n",
       "SkinThickness             0.448859  0.393760                  0.178299   \n",
       "Insulin                   1.000000  0.223012                  0.192719   \n",
       "BMI                       0.223012  1.000000                  0.125719   \n",
       "DiabetesPedigreeFunction  0.192719  0.125719                  1.000000   \n",
       "Age                      -0.085879  0.038987                  0.026569   \n",
       "Outcome                   0.120924  0.276726                  0.155459   \n",
       "\n",
       "                               Age   Outcome  \n",
       "Pregnancies               0.539457  0.224437  \n",
       "Glucose                   0.254496  0.458421  \n",
       "BloodPressure             0.238375  0.075958  \n",
       "SkinThickness            -0.111034  0.076040  \n",
       "Insulin                  -0.085879  0.120924  \n",
       "BMI                       0.038987  0.276726  \n",
       "DiabetesPedigreeFunction  0.026569  0.155459  \n",
       "Age                       1.000000  0.236509  \n",
       "Outcome                   0.236509  1.000000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6f262568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4c402",
   "metadata": {},
   "source": [
    "# Spliting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c9fd0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the independent variables and dependent variables\n",
    "y = df['Outcome']\n",
    "X = df.iloc[:,[0,1,2,3,4,5,6,7]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e4e509bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            2      138             62             35        0  33.6   \n",
       "1            0       84             82             31      125  38.2   \n",
       "2            0      145              0              0        0  44.2   \n",
       "3            0      135             68             42      250  42.3   \n",
       "4            1      139             62             41      480  40.7   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  \n",
       "0                     0.127   47  \n",
       "1                     0.233   23  \n",
       "2                     0.630   31  \n",
       "3                     0.365   24  \n",
       "4                     0.536   21  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6ea35d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "81547944",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ac0bf2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a81f9545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3c54d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def cross_val(model):\n",
    "    pred = cross_val_score(model, X, y, cv=10)\n",
    "    return pred.mean()\n",
    "\n",
    "def print_evaluate(true, predicted):  \n",
    "    acc = metrics.accuracy_score(true, predicted)\n",
    "    pre = metrics.precision_score(true, predicted)\n",
    "    rec = metrics.recall_score(true, predicted)\n",
    "    f1 = metrics.f1_score(true, predicted)\n",
    "    print('Accuracy:', acc)\n",
    "    print('Precision:', pre)      \n",
    "    print('ReCall:', rec)\n",
    "    print('F1 Score', f1)\n",
    "    print('__________________________________')\n",
    "    \n",
    "def evaluate(true, predicted):\n",
    "    acc = metrics.accuracy_score(true, predicted)\n",
    "    pre = metrics.precision_score(true, predicted)\n",
    "    rec = metrics.recall_score(true, predicted)\n",
    "    f1 = metrics.f1_score(true, predicted)\n",
    "    return acc,pre,rec,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ee916069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('std_scalar', StandardScaler())\n",
    "])\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f8f3e9",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER FOR DECISION TREE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f7b75e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "12610bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Randomized Search CV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "# max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "#The function to measure the quality of a split. \n",
    "criterion = ['gini','entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f1eeb0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [5, 10, 15, 20, 25, 30], 'min_samples_split': [2, 5, 10, 15, 100], 'min_samples_leaf': [1, 2, 5, 10], 'criterion': ['gini', 'entropy']}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'criterion':criterion}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a00a0f6",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b6ce09f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] min_samples_split=2, min_samples_leaf=1, max_features=log2, max_depth=30, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=1, max_features=log2, max_depth=30, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=1, max_features=log2, max_depth=30, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=1, max_features=log2, max_depth=30, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=1, max_features=log2, max_depth=30, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=1, max_features=log2, max_depth=30, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=1, max_features=log2, max_depth=30, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=1, max_features=log2, max_depth=30, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=1, max_features=log2, max_depth=30, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=1, max_features=log2, max_depth=30, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=100, min_samples_leaf=5, max_features=log2, max_depth=5, criterion=gini \n",
      "[CV]  min_samples_split=100, min_samples_leaf=5, max_features=log2, max_depth=5, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=100, min_samples_leaf=5, max_features=log2, max_depth=5, criterion=gini \n",
      "[CV]  min_samples_split=100, min_samples_leaf=5, max_features=log2, max_depth=5, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=100, min_samples_leaf=5, max_features=log2, max_depth=5, criterion=gini \n",
      "[CV]  min_samples_split=100, min_samples_leaf=5, max_features=log2, max_depth=5, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=100, min_samples_leaf=5, max_features=log2, max_depth=5, criterion=gini \n",
      "[CV]  min_samples_split=100, min_samples_leaf=5, max_features=log2, max_depth=5, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=100, min_samples_leaf=5, max_features=log2, max_depth=5, criterion=gini \n",
      "[CV]  min_samples_split=100, min_samples_leaf=5, max_features=log2, max_depth=5, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=10, max_features=auto, max_depth=20, criterion=gini \n",
      "[CV]  min_samples_split=15, min_samples_leaf=10, max_features=auto, max_depth=20, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=10, max_features=auto, max_depth=20, criterion=gini \n",
      "[CV]  min_samples_split=15, min_samples_leaf=10, max_features=auto, max_depth=20, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=10, max_features=auto, max_depth=20, criterion=gini \n",
      "[CV]  min_samples_split=15, min_samples_leaf=10, max_features=auto, max_depth=20, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=10, max_features=auto, max_depth=20, criterion=gini \n",
      "[CV]  min_samples_split=15, min_samples_leaf=10, max_features=auto, max_depth=20, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=10, max_features=auto, max_depth=20, criterion=gini \n",
      "[CV]  min_samples_split=15, min_samples_leaf=10, max_features=auto, max_depth=20, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=10, criterion=entropy \n",
      "[CV]  min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=10, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=10, criterion=entropy \n",
      "[CV]  min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=10, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=10, criterion=entropy \n",
      "[CV]  min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=10, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=10, criterion=entropy \n",
      "[CV]  min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=10, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=10, criterion=entropy \n",
      "[CV]  min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=10, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=10, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=10, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=10, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=10, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=10, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  min_samples_split=15, min_samples_leaf=1, max_features=auto, max_depth=10, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=15, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=15, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=15, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=15, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=15, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=15, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=15, criterion=gini \n",
      "[CV]  min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=15, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=15, criterion=gini \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=15, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini \n",
      "[CV]  min_samples_split=10, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini \n",
      "[CV]  min_samples_split=10, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini \n",
      "[CV]  min_samples_split=10, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini \n",
      "[CV]  min_samples_split=10, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini \n",
      "[CV]  min_samples_split=10, min_samples_leaf=5, max_features=log2, max_depth=25, criterion=gini, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=5, max_features=sqrt, max_depth=5, criterion=entropy \n",
      "[CV]  min_samples_split=2, min_samples_leaf=5, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=5, max_features=sqrt, max_depth=5, criterion=entropy \n",
      "[CV]  min_samples_split=2, min_samples_leaf=5, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=5, max_features=sqrt, max_depth=5, criterion=entropy \n",
      "[CV]  min_samples_split=2, min_samples_leaf=5, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=5, max_features=sqrt, max_depth=5, criterion=entropy \n",
      "[CV]  min_samples_split=2, min_samples_leaf=5, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.0s\n",
      "[CV] min_samples_split=2, min_samples_leaf=5, max_features=sqrt, max_depth=5, criterion=entropy \n",
      "[CV]  min_samples_split=2, min_samples_leaf=5, max_features=sqrt, max_depth=5, criterion=entropy, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=DecisionTreeClassifier(), n_jobs=1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [5, 10, 15, 20, 25, 30],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 5, 10],\n",
       "                                        'min_samples_split': [2, 5, 10, 15,\n",
       "                                                              100]},\n",
       "                   random_state=42, scoring='neg_mean_squared_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt= RandomizedSearchCV(estimator = dt, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, verbose=2, random_state=42, n_jobs = 1)\n",
    "dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d01308d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8ff62be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.898\n",
      "Precision: 0.8660436137071651\n",
      "ReCall: 0.8249258160237388\n",
      "F1 Score 0.844984802431611\n",
      "__________________________________\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.556\n",
      "Precision: 0.34890965732087226\n",
      "ReCall: 0.3227665706051873\n",
      "F1 Score 0.3353293413173653\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "test_pred =  dt.predict(X_test)\n",
    "train_pred =  dt.predict(X_test)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2b856ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ReCall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.866044</td>\n",
       "      <td>0.824926</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Precision    ReCall  F1 Score  Cross Validation\n",
       "0  Decision Tree     0.898   0.866044  0.824926  0.844985             0.992"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(data=[[\"Decision Tree\", *evaluate(y_test, test_pred) , cross_val(DecisionTreeClassifier())]], \n",
    "                          columns=[\"Model\",\"Accuracy\",\"Precision\",\"ReCall\",\"F1 Score\",\"Cross Validation\"])\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8ffc65",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER FOR RANDOM FOREST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2856a523",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Randomized Search CV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1200, num = 12)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 30, num = 6)]\n",
    "# max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "#The function to measure the quality of a split. \n",
    "criterion = ['gini','entropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f5cb64a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [5, 10, 15, 20, 25, 30], 'min_samples_split': [2, 5, 10, 15, 100], 'min_samples_leaf': [1, 2, 5, 10], 'criterion': ['gini', 'entropy']}\n"
     ]
    }
   ],
   "source": [
    " #Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'criterion':criterion}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d6c992",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "44f0ea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=1100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=25, criterion=entropy \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=25, criterion=entropy, total=   2.3s\n",
      "[CV] n_estimators=1100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=25, criterion=entropy \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=25, criterion=entropy, total=   2.3s\n",
      "[CV] n_estimators=1100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=25, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=25, criterion=entropy, total=   2.4s\n",
      "[CV] n_estimators=1100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=25, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=25, criterion=entropy, total=   3.0s\n",
      "[CV] n_estimators=1100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=25, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=2, min_samples_leaf=2, max_features=auto, max_depth=25, criterion=entropy, total=   2.5s\n",
      "[CV] n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=gini, total=   1.8s\n",
      "[CV] n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=gini, total=   1.8s\n",
      "[CV] n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=gini, total=   1.8s\n",
      "[CV] n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=gini, total=   1.8s\n",
      "[CV] n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=gini \n",
      "[CV]  n_estimators=900, min_samples_split=5, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=gini, total=   1.8s\n",
      "[CV] n_estimators=300, min_samples_split=100, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=300, min_samples_split=100, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=entropy, total=   0.6s\n",
      "[CV] n_estimators=300, min_samples_split=100, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=300, min_samples_split=100, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=entropy, total=   0.5s\n",
      "[CV] n_estimators=300, min_samples_split=100, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=300, min_samples_split=100, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=entropy, total=   0.6s\n",
      "[CV] n_estimators=300, min_samples_split=100, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=300, min_samples_split=100, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=entropy, total=   0.5s\n",
      "[CV] n_estimators=300, min_samples_split=100, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=300, min_samples_split=100, min_samples_leaf=2, max_features=sqrt, max_depth=10, criterion=entropy, total=   0.5s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=entropy, total=   1.7s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=entropy, total=   1.7s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=entropy, total=   1.8s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=entropy, total=   2.5s\n",
      "[CV] n_estimators=800, min_samples_split=10, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=800, min_samples_split=10, min_samples_leaf=5, max_features=auto, max_depth=10, criterion=entropy, total=   2.0s\n",
      "[CV] n_estimators=1100, min_samples_split=10, min_samples_leaf=10, max_features=log2, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=10, min_samples_leaf=10, max_features=log2, max_depth=10, criterion=entropy, total=   2.7s\n",
      "[CV] n_estimators=1100, min_samples_split=10, min_samples_leaf=10, max_features=log2, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=10, min_samples_leaf=10, max_features=log2, max_depth=10, criterion=entropy, total=   3.4s\n",
      "[CV] n_estimators=1100, min_samples_split=10, min_samples_leaf=10, max_features=log2, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=10, min_samples_leaf=10, max_features=log2, max_depth=10, criterion=entropy, total=   2.5s\n",
      "[CV] n_estimators=1100, min_samples_split=10, min_samples_leaf=10, max_features=log2, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=10, min_samples_leaf=10, max_features=log2, max_depth=10, criterion=entropy, total=   2.3s\n",
      "[CV] n_estimators=1100, min_samples_split=10, min_samples_leaf=10, max_features=log2, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=10, min_samples_leaf=10, max_features=log2, max_depth=10, criterion=entropy, total=   2.3s\n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=1, max_features=log2, max_depth=15, criterion=entropy \n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=1, max_features=log2, max_depth=15, criterion=entropy, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=1, max_features=log2, max_depth=15, criterion=entropy \n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=1, max_features=log2, max_depth=15, criterion=entropy, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=1, max_features=log2, max_depth=15, criterion=entropy \n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=1, max_features=log2, max_depth=15, criterion=entropy, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=1, max_features=log2, max_depth=15, criterion=entropy \n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=1, max_features=log2, max_depth=15, criterion=entropy, total=   0.5s\n",
      "[CV] n_estimators=200, min_samples_split=10, min_samples_leaf=1, max_features=log2, max_depth=15, criterion=entropy \n",
      "[CV]  n_estimators=200, min_samples_split=10, min_samples_leaf=1, max_features=log2, max_depth=15, criterion=entropy, total=   0.5s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, criterion=gini \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, criterion=gini, total=   1.9s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, criterion=gini \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, criterion=gini, total=   1.9s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, criterion=gini \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, criterion=gini, total=   1.9s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, criterion=gini \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, criterion=gini, total=   1.9s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, criterion=gini \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=10, max_features=sqrt, max_depth=5, criterion=gini, total=   1.9s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=2, max_features=auto, max_depth=5, criterion=entropy \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=2, max_features=auto, max_depth=5, criterion=entropy, total=   2.1s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=2, max_features=auto, max_depth=5, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=2, max_features=auto, max_depth=5, criterion=entropy, total=   2.0s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=2, max_features=auto, max_depth=5, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=2, max_features=auto, max_depth=5, criterion=entropy, total=   2.0s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=2, max_features=auto, max_depth=5, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=2, max_features=auto, max_depth=5, criterion=entropy, total=   2.1s\n",
      "[CV] n_estimators=1100, min_samples_split=15, min_samples_leaf=2, max_features=auto, max_depth=5, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=15, min_samples_leaf=2, max_features=auto, max_depth=5, criterion=entropy, total=   2.9s\n",
      "[CV] n_estimators=1100, min_samples_split=100, min_samples_leaf=1, max_features=log2, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=100, min_samples_leaf=1, max_features=log2, max_depth=10, criterion=entropy, total=   2.7s\n",
      "[CV] n_estimators=1100, min_samples_split=100, min_samples_leaf=1, max_features=log2, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=100, min_samples_leaf=1, max_features=log2, max_depth=10, criterion=entropy, total=   2.9s\n",
      "[CV] n_estimators=1100, min_samples_split=100, min_samples_leaf=1, max_features=log2, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=100, min_samples_leaf=1, max_features=log2, max_depth=10, criterion=entropy, total=   2.2s\n",
      "[CV] n_estimators=1100, min_samples_split=100, min_samples_leaf=1, max_features=log2, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=100, min_samples_leaf=1, max_features=log2, max_depth=10, criterion=entropy, total=   2.3s\n",
      "[CV] n_estimators=1100, min_samples_split=100, min_samples_leaf=1, max_features=log2, max_depth=10, criterion=entropy \n",
      "[CV]  n_estimators=1100, min_samples_split=100, min_samples_leaf=1, max_features=log2, max_depth=10, criterion=entropy, total=   2.4s\n",
      "[CV] n_estimators=700, min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=30, criterion=entropy \n",
      "[CV]  n_estimators=700, min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=30, criterion=entropy, total=   1.3s\n",
      "[CV] n_estimators=700, min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=30, criterion=entropy \n",
      "[CV]  n_estimators=700, min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=30, criterion=entropy, total=   1.3s\n",
      "[CV] n_estimators=700, min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=30, criterion=entropy \n",
      "[CV]  n_estimators=700, min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=30, criterion=entropy, total=   1.4s\n",
      "[CV] n_estimators=700, min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=30, criterion=entropy \n",
      "[CV]  n_estimators=700, min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=30, criterion=entropy, total=   1.4s\n",
      "[CV] n_estimators=700, min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=30, criterion=entropy \n",
      "[CV]  n_estimators=700, min_samples_split=15, min_samples_leaf=5, max_features=sqrt, max_depth=30, criterion=entropy, total=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=1,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [5, 10, 15, 20, 25, 30],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 5, 10],\n",
       "                                        'min_samples_split': [2, 5, 10, 15,\n",
       "                                                              100],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000, 1100,\n",
       "                                                         1200]},\n",
       "                   random_state=42, scoring='neg_mean_squared_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf = RandomizedSearchCV(estimator = rf, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9e8af54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9524c19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.912\n",
      "Precision: 0.8738738738738738\n",
      "ReCall: 0.8635014836795252\n",
      "F1 Score 0.8686567164179103\n",
      "__________________________________\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.554\n",
      "Precision: 0.35135135135135137\n",
      "ReCall: 0.3371757925072046\n",
      "F1 Score 0.34411764705882353\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "test_pred =  rf.predict(X_test)\n",
    "train_pred =  rf.predict(X_test)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e4a80a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ReCall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.866044</td>\n",
       "      <td>0.824926</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.863501</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>0.992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Precision    ReCall  F1 Score  Cross Validation\n",
       "0  Decision Tree     0.898   0.866044  0.824926  0.844985             0.992\n",
       "1  Random Forest     0.912   0.873874  0.863501  0.868657             0.992"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Random Forest\", *evaluate(y_test, test_pred) , cross_val(RandomForestClassifier())]], \n",
    "                          columns=[\"Model\",\"Accuracy\",\"Precision\",\"ReCall\",\"F1 Score\",\"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf997f",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER FOR LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa2d132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to specify the norm used in the penalization\n",
    "penalty=['l1', 'l2','elasticnet','none']\n",
    "#Algorithm to use in the optimization problem.\n",
    "solver=['newton-cg','lbfgs','liblinear','sag','saga']\n",
    "#multi-class\n",
    "multi_class=['auto','ovr','multinomia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "105ec6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'multi_class': ['auto', 'ovr', 'multinomia']}\n"
     ]
    }
   ],
   "source": [
    " #Create the random grid\n",
    "random_grid = {'penalty':penalty,\n",
    "               'solver':solver,\n",
    "               'multi_class':multi_class\n",
    "              }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8282dba2",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ed097088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] solver=newton-cg, penalty=l1, multi_class=auto ..................\n",
      "[CV] ... solver=newton-cg, penalty=l1, multi_class=auto, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, multi_class=auto ..................\n",
      "[CV] ... solver=newton-cg, penalty=l1, multi_class=auto, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, multi_class=auto ..................\n",
      "[CV] ... solver=newton-cg, penalty=l1, multi_class=auto, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, multi_class=auto ..................\n",
      "[CV] ... solver=newton-cg, penalty=l1, multi_class=auto, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, multi_class=auto ..................\n",
      "[CV] ... solver=newton-cg, penalty=l1, multi_class=auto, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, multi_class=auto ..................\n",
      "[CV] ... solver=newton-cg, penalty=l2, multi_class=auto, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, multi_class=auto ..................\n",
      "[CV] ... solver=newton-cg, penalty=l2, multi_class=auto, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, multi_class=auto ..................\n",
      "[CV] ... solver=newton-cg, penalty=l2, multi_class=auto, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, multi_class=auto ..................\n",
      "[CV] ... solver=newton-cg, penalty=l2, multi_class=auto, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, multi_class=auto ..................\n",
      "[CV] ... solver=newton-cg, penalty=l2, multi_class=auto, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=none, multi_class=ovr .....................\n",
      "[CV] ...... solver=lbfgs, penalty=none, multi_class=ovr, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=none, multi_class=ovr .....................\n",
      "[CV] ...... solver=lbfgs, penalty=none, multi_class=ovr, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=none, multi_class=ovr .....................\n",
      "[CV] ...... solver=lbfgs, penalty=none, multi_class=ovr, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=none, multi_class=ovr .....................\n",
      "[CV] ...... solver=lbfgs, penalty=none, multi_class=ovr, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=none, multi_class=ovr .....................\n",
      "[CV] ...... solver=lbfgs, penalty=none, multi_class=ovr, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, multi_class=multinomia ............\n",
      "[CV]  solver=newton-cg, penalty=l2, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, multi_class=multinomia ............\n",
      "[CV]  solver=newton-cg, penalty=l2, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, multi_class=multinomia ............\n",
      "[CV]  solver=newton-cg, penalty=l2, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, multi_class=multinomia ............\n",
      "[CV]  solver=newton-cg, penalty=l2, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, multi_class=multinomia ............\n",
      "[CV]  solver=newton-cg, penalty=l2, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, multi_class=auto ................\n",
      "[CV] . solver=sag, penalty=elasticnet, multi_class=auto, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, multi_class=auto ................\n",
      "[CV] . solver=sag, penalty=elasticnet, multi_class=auto, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, multi_class=auto ................\n",
      "[CV] . solver=sag, penalty=elasticnet, multi_class=auto, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, multi_class=auto ................\n",
      "[CV] . solver=sag, penalty=elasticnet, multi_class=auto, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, multi_class=auto ................\n",
      "[CV] . solver=sag, penalty=elasticnet, multi_class=auto, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, multi_class=multinomia .........\n",
      "[CV]  solver=saga, penalty=elasticnet, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, multi_class=multinomia .........\n",
      "[CV]  solver=saga, penalty=elasticnet, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, multi_class=multinomia .........\n",
      "[CV]  solver=saga, penalty=elasticnet, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, multi_class=multinomia .........\n",
      "[CV]  solver=saga, penalty=elasticnet, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, multi_class=multinomia .........\n",
      "[CV]  solver=saga, penalty=elasticnet, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, multi_class=ovr .................\n",
      "[CV] .. solver=sag, penalty=elasticnet, multi_class=ovr, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, multi_class=ovr .................\n",
      "[CV] .. solver=sag, penalty=elasticnet, multi_class=ovr, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, multi_class=ovr .................\n",
      "[CV] .. solver=sag, penalty=elasticnet, multi_class=ovr, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, multi_class=ovr .................\n",
      "[CV] .. solver=sag, penalty=elasticnet, multi_class=ovr, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, multi_class=ovr .................\n",
      "[CV] .. solver=sag, penalty=elasticnet, multi_class=ovr, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, multi_class=multinomia ..................\n",
      "[CV] ... solver=sag, penalty=l2, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, multi_class=multinomia ..................\n",
      "[CV] ... solver=sag, penalty=l2, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, multi_class=multinomia ..................\n",
      "[CV] ... solver=sag, penalty=l2, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, multi_class=multinomia ..................\n",
      "[CV] ... solver=sag, penalty=l2, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, multi_class=multinomia ..................\n",
      "[CV] ... solver=sag, penalty=l2, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=elasticnet, multi_class=auto ..........\n",
      "[CV]  solver=liblinear, penalty=elasticnet, multi_class=auto, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=elasticnet, multi_class=auto ..........\n",
      "[CV]  solver=liblinear, penalty=elasticnet, multi_class=auto, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=elasticnet, multi_class=auto .........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  solver=liblinear, penalty=elasticnet, multi_class=auto, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=elasticnet, multi_class=auto ..........\n",
      "[CV]  solver=liblinear, penalty=elasticnet, multi_class=auto, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=elasticnet, multi_class=auto ..........\n",
      "[CV]  solver=liblinear, penalty=elasticnet, multi_class=auto, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=none, multi_class=multinomia ..........\n",
      "[CV]  solver=liblinear, penalty=none, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=none, multi_class=multinomia ..........\n",
      "[CV]  solver=liblinear, penalty=none, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=none, multi_class=multinomia ..........\n",
      "[CV]  solver=liblinear, penalty=none, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=none, multi_class=multinomia ..........\n",
      "[CV]  solver=liblinear, penalty=none, multi_class=multinomia, total=   0.0s\n",
      "[CV] solver=liblinear, penalty=none, multi_class=multinomia ..........\n",
      "[CV]  solver=liblinear, penalty=none, multi_class=multinomia, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=1,\n",
       "                   param_distributions={'multi_class': ['auto', 'ovr',\n",
       "                                                        'multinomia'],\n",
       "                                        'penalty': ['l1', 'l2', 'elasticnet',\n",
       "                                                    'none'],\n",
       "                                        'solver': ['newton-cg', 'lbfgs',\n",
       "                                                   'liblinear', 'sag',\n",
       "                                                   'saga']},\n",
       "                   random_state=42, scoring='neg_mean_squared_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr = RandomizedSearchCV(estimator = lr, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b75b4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b4229d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.792\n",
      "Precision: 0.7509727626459144\n",
      "ReCall: 0.5727002967359051\n",
      "F1 Score 0.6498316498316499\n",
      "__________________________________\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.554\n",
      "Precision: 0.30739299610894943\n",
      "ReCall: 0.2276657060518732\n",
      "F1 Score 0.26158940397350994\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "test_pred =  lr.predict(X_test)\n",
    "train_pred =  lr.predict(X_test)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "544d1b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ReCall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.866044</td>\n",
       "      <td>0.824926</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>0.9920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.863501</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>0.9920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>0.572700</td>\n",
       "      <td>0.649832</td>\n",
       "      <td>0.7785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Precision    ReCall  F1 Score  \\\n",
       "0       Decision Tree     0.898   0.866044  0.824926  0.844985   \n",
       "1       Random Forest     0.912   0.873874  0.863501  0.868657   \n",
       "0  LogisticRegression     0.792   0.750973  0.572700  0.649832   \n",
       "\n",
       "   Cross Validation  \n",
       "0            0.9920  \n",
       "1            0.9920  \n",
       "0            0.7785  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"LogisticRegression\", *evaluate(y_test, test_pred) , cross_val(LogisticRegression())]], \n",
    "                          columns=[\"Model\",\"Accuracy\",\"Precision\",\"ReCall\",\"F1 Score\",\"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2,)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e936c2b",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER FOR KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9f94192e",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Randomized Search CV\n",
    "\n",
    "#Number of neighbors to use\n",
    "n_neighbors = [2,3,4,5,6,7,8]\n",
    "#Algorithm used to compute the nearest neighbors:\n",
    "algorithm=['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "#weight function used in prediction\n",
    "weights=['uniform', 'distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4af2644c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [2, 3, 4, 5, 6, 7, 8], 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'], 'weights': ['uniform', 'distance']}\n"
     ]
    }
   ],
   "source": [
    " #Create the random grid\n",
    "random_grid = {'n_neighbors':n_neighbors,\n",
    "               'algorithm':algorithm,\n",
    "               'weights':weights\n",
    "              }\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98af71c",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "acf8a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d4fe2292",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn = RandomizedSearchCV(estimator = knn, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3f3f27c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] weights=uniform, n_neighbors=2, algorithm=auto ..................\n",
      "[CV] ... weights=uniform, n_neighbors=2, algorithm=auto, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=2, algorithm=auto ..................\n",
      "[CV] ... weights=uniform, n_neighbors=2, algorithm=auto, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=2, algorithm=auto ..................\n",
      "[CV] ... weights=uniform, n_neighbors=2, algorithm=auto, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=2, algorithm=auto ..................\n",
      "[CV] ... weights=uniform, n_neighbors=2, algorithm=auto, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=2, algorithm=auto ..................\n",
      "[CV] ... weights=uniform, n_neighbors=2, algorithm=auto, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=auto .................\n",
      "[CV] .. weights=distance, n_neighbors=4, algorithm=auto, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=auto .................\n",
      "[CV] .. weights=distance, n_neighbors=4, algorithm=auto, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=auto .................\n",
      "[CV] .. weights=distance, n_neighbors=4, algorithm=auto, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=auto .................\n",
      "[CV] .. weights=distance, n_neighbors=4, algorithm=auto, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=auto .................\n",
      "[CV] .. weights=distance, n_neighbors=4, algorithm=auto, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=kd_tree ..............\n",
      "[CV]  weights=distance, n_neighbors=4, algorithm=kd_tree, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=kd_tree ..............\n",
      "[CV]  weights=distance, n_neighbors=4, algorithm=kd_tree, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=kd_tree ..............\n",
      "[CV]  weights=distance, n_neighbors=4, algorithm=kd_tree, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=kd_tree ..............\n",
      "[CV]  weights=distance, n_neighbors=4, algorithm=kd_tree, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=kd_tree ..............\n",
      "[CV]  weights=distance, n_neighbors=4, algorithm=kd_tree, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=8, algorithm=auto .................\n",
      "[CV] .. weights=distance, n_neighbors=8, algorithm=auto, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=8, algorithm=auto .................\n",
      "[CV] .. weights=distance, n_neighbors=8, algorithm=auto, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=8, algorithm=auto .................\n",
      "[CV] .. weights=distance, n_neighbors=8, algorithm=auto, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=8, algorithm=auto .................\n",
      "[CV] .. weights=distance, n_neighbors=8, algorithm=auto, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=8, algorithm=auto .................\n",
      "[CV] .. weights=distance, n_neighbors=8, algorithm=auto, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=ball_tree ............\n",
      "[CV]  weights=distance, n_neighbors=4, algorithm=ball_tree, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=ball_tree ............\n",
      "[CV]  weights=distance, n_neighbors=4, algorithm=ball_tree, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=ball_tree ............\n",
      "[CV]  weights=distance, n_neighbors=4, algorithm=ball_tree, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=ball_tree ............\n",
      "[CV]  weights=distance, n_neighbors=4, algorithm=ball_tree, total=   0.0s\n",
      "[CV] weights=distance, n_neighbors=4, algorithm=ball_tree ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  weights=distance, n_neighbors=4, algorithm=ball_tree, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=6, algorithm=brute .................\n",
      "[CV] .. weights=uniform, n_neighbors=6, algorithm=brute, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=6, algorithm=brute .................\n",
      "[CV] .. weights=uniform, n_neighbors=6, algorithm=brute, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=6, algorithm=brute .................\n",
      "[CV] .. weights=uniform, n_neighbors=6, algorithm=brute, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=6, algorithm=brute .................\n",
      "[CV] .. weights=uniform, n_neighbors=6, algorithm=brute, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=6, algorithm=brute .................\n",
      "[CV] .. weights=uniform, n_neighbors=6, algorithm=brute, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=6, algorithm=kd_tree ...............\n",
      "[CV]  weights=uniform, n_neighbors=6, algorithm=kd_tree, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=6, algorithm=kd_tree ...............\n",
      "[CV]  weights=uniform, n_neighbors=6, algorithm=kd_tree, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=6, algorithm=kd_tree ...............\n",
      "[CV]  weights=uniform, n_neighbors=6, algorithm=kd_tree, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=6, algorithm=kd_tree ...............\n",
      "[CV]  weights=uniform, n_neighbors=6, algorithm=kd_tree, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=6, algorithm=kd_tree ...............\n",
      "[CV]  weights=uniform, n_neighbors=6, algorithm=kd_tree, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=8, algorithm=ball_tree .............\n",
      "[CV]  weights=uniform, n_neighbors=8, algorithm=ball_tree, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=8, algorithm=ball_tree .............\n",
      "[CV]  weights=uniform, n_neighbors=8, algorithm=ball_tree, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=8, algorithm=ball_tree .............\n",
      "[CV]  weights=uniform, n_neighbors=8, algorithm=ball_tree, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=8, algorithm=ball_tree .............\n",
      "[CV]  weights=uniform, n_neighbors=8, algorithm=ball_tree, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=8, algorithm=ball_tree .............\n",
      "[CV]  weights=uniform, n_neighbors=8, algorithm=ball_tree, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=3, algorithm=brute .................\n",
      "[CV] .. weights=uniform, n_neighbors=3, algorithm=brute, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=3, algorithm=brute .................\n",
      "[CV] .. weights=uniform, n_neighbors=3, algorithm=brute, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=3, algorithm=brute .................\n",
      "[CV] .. weights=uniform, n_neighbors=3, algorithm=brute, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=3, algorithm=brute .................\n",
      "[CV] .. weights=uniform, n_neighbors=3, algorithm=brute, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=3, algorithm=brute .................\n",
      "[CV] .. weights=uniform, n_neighbors=3, algorithm=brute, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=8, algorithm=auto ..................\n",
      "[CV] ... weights=uniform, n_neighbors=8, algorithm=auto, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=8, algorithm=auto ..................\n",
      "[CV] ... weights=uniform, n_neighbors=8, algorithm=auto, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=8, algorithm=auto ..................\n",
      "[CV] ... weights=uniform, n_neighbors=8, algorithm=auto, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=8, algorithm=auto ..................\n",
      "[CV] ... weights=uniform, n_neighbors=8, algorithm=auto, total=   0.0s\n",
      "[CV] weights=uniform, n_neighbors=8, algorithm=auto ..................\n",
      "[CV] ... weights=uniform, n_neighbors=8, algorithm=auto, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=KNeighborsClassifier(n_neighbors=1),\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={'algorithm': ['auto', 'ball_tree',\n",
       "                                                      'kd_tree', 'brute'],\n",
       "                                        'n_neighbors': [2, 3, 4, 5, 6, 7, 8],\n",
       "                                        'weights': ['uniform', 'distance']},\n",
       "                   random_state=42, scoring='neg_mean_squared_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1d1fc88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a9506e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.906\n",
      "Precision: 0.8670694864048338\n",
      "ReCall: 0.8516320474777448\n",
      "F1 Score 0.8592814371257484\n",
      "__________________________________\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.532\n",
      "Precision: 0.31722054380664655\n",
      "ReCall: 0.3025936599423631\n",
      "F1 Score 0.3097345132743363\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "test_pred =  knn.predict(X_test)\n",
    "train_pred =  knn.predict(X_test)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8a1836b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ReCall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.866044</td>\n",
       "      <td>0.824926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.863501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.649832</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.859281</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.867069</td>\n",
       "      <td>0.851632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Cross Validation  F1 Score               Model  Precision  \\\n",
       "0     0.898            0.9920  0.844985       Decision Tree   0.866044   \n",
       "1     0.912            0.9920  0.868657       Random Forest   0.873874   \n",
       "2     0.792            0.7785  0.649832  LogisticRegression   0.750973   \n",
       "3     0.906            0.8020  0.859281                 KNN   0.867069   \n",
       "\n",
       "     ReCall  \n",
       "0  0.824926  \n",
       "1  0.863501  \n",
       "2  0.572700  \n",
       "3  0.851632  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"KNN\", *evaluate(y_test, test_pred) , cross_val(KNeighborsClassifier())]], \n",
    "                          columns=[\"Model\",\"Accuracy\",\"Precision\",\"ReCall\",\"F1 Score\",\"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True,sort = True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c791d69d",
   "metadata": {},
   "source": [
    "#  Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "401d19b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "14f13834",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9e68e48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.791\n",
      "Precision: 0.7105263157894737\n",
      "ReCall: 0.6409495548961425\n",
      "F1 Score 0.6739469578783152\n",
      "__________________________________\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.551\n",
      "Precision: 0.33223684210526316\n",
      "ReCall: 0.2910662824207493\n",
      "F1 Score 0.3102918586789554\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "test_pred =  gnb.predict(X_test)\n",
    "train_pred =  gnb.predict(X_test)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3b5c31dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ReCall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.866044</td>\n",
       "      <td>0.824926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.863501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.649832</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.859281</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.867069</td>\n",
       "      <td>0.851632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.673947</td>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.640950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Cross Validation  F1 Score               Model  Precision  \\\n",
       "0     0.898            0.9920  0.844985       Decision Tree   0.866044   \n",
       "1     0.912            0.9920  0.868657       Random Forest   0.873874   \n",
       "2     0.792            0.7785  0.649832  LogisticRegression   0.750973   \n",
       "3     0.906            0.8020  0.859281                 KNN   0.867069   \n",
       "4     0.791            0.7555  0.673947         Naïve Bayes   0.710526   \n",
       "\n",
       "     ReCall  \n",
       "0  0.824926  \n",
       "1  0.863501  \n",
       "2  0.572700  \n",
       "3  0.851632  \n",
       "4  0.640950  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"Naïve Bayes\", *evaluate(y_test, test_pred) , cross_val( GaussianNB())]], \n",
    "                          columns=[\"Model\",\"Accuracy\",\"Precision\",\"ReCall\",\"F1 Score\",\"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True,sort = True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bcf816",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER IN Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "34b768e0",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Randomized Search CV\n",
    "    \n",
    "loss = ['hinge','log','modified_huber','squared_hinge','perceptron']\n",
    "penalty = ['l2','l1','elasticnet'] \n",
    "class_weight = ['weight','balanced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b765c85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'], 'penalty': ['l2', 'l1', 'elasticnet'], 'class_weight': ['weight', 'balanced']}\n"
     ]
    }
   ],
   "source": [
    " #Create the random grid\n",
    "random_grid = {'loss':loss,\n",
    "               'penalty':penalty,\n",
    "               'class_weight':class_weight}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4b576b",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a1ee4fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] penalty=l2, loss=perceptron, class_weight=balanced ..............\n",
      "[CV]  penalty=l2, loss=perceptron, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=perceptron, class_weight=balanced ..............\n",
      "[CV]  penalty=l2, loss=perceptron, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=perceptron, class_weight=balanced ..............\n",
      "[CV]  penalty=l2, loss=perceptron, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=perceptron, class_weight=balanced ..............\n",
      "[CV]  penalty=l2, loss=perceptron, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=perceptron, class_weight=balanced ..............\n",
      "[CV]  penalty=l2, loss=perceptron, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=hinge, class_weight=balanced ...................\n",
      "[CV] .... penalty=l2, loss=hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=hinge, class_weight=balanced ...................\n",
      "[CV] .... penalty=l2, loss=hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=hinge, class_weight=balanced ...................\n",
      "[CV] .... penalty=l2, loss=hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=hinge, class_weight=balanced ...................\n",
      "[CV] .... penalty=l2, loss=hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=hinge, class_weight=balanced ...................\n",
      "[CV] .... penalty=l2, loss=hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=modified_huber, class_weight=balanced ..\n",
      "[CV]  penalty=elasticnet, loss=modified_huber, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=modified_huber, class_weight=balanced ..\n",
      "[CV]  penalty=elasticnet, loss=modified_huber, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=modified_huber, class_weight=balanced ..\n",
      "[CV]  penalty=elasticnet, loss=modified_huber, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=modified_huber, class_weight=balanced ..\n",
      "[CV]  penalty=elasticnet, loss=modified_huber, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=modified_huber, class_weight=balanced ..\n",
      "[CV]  penalty=elasticnet, loss=modified_huber, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=hinge, class_weight=balanced ...........\n",
      "[CV]  penalty=elasticnet, loss=hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=hinge, class_weight=balanced ...........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  penalty=elasticnet, loss=hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=hinge, class_weight=balanced ...........\n",
      "[CV]  penalty=elasticnet, loss=hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=hinge, class_weight=balanced ...........\n",
      "[CV]  penalty=elasticnet, loss=hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=hinge, class_weight=balanced ...........\n",
      "[CV]  penalty=elasticnet, loss=hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=modified_huber, class_weight=weight ....\n",
      "[CV]  penalty=elasticnet, loss=modified_huber, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=modified_huber, class_weight=weight ....\n",
      "[CV]  penalty=elasticnet, loss=modified_huber, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=modified_huber, class_weight=weight ....\n",
      "[CV]  penalty=elasticnet, loss=modified_huber, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=modified_huber, class_weight=weight ....\n",
      "[CV]  penalty=elasticnet, loss=modified_huber, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=elasticnet, loss=modified_huber, class_weight=weight ....\n",
      "[CV]  penalty=elasticnet, loss=modified_huber, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=squared_hinge, class_weight=weight .............\n",
      "[CV]  penalty=l2, loss=squared_hinge, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=squared_hinge, class_weight=weight .............\n",
      "[CV]  penalty=l2, loss=squared_hinge, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=squared_hinge, class_weight=weight .............\n",
      "[CV]  penalty=l2, loss=squared_hinge, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=squared_hinge, class_weight=weight .............\n",
      "[CV]  penalty=l2, loss=squared_hinge, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=squared_hinge, class_weight=weight .............\n",
      "[CV]  penalty=l2, loss=squared_hinge, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l1, loss=perceptron, class_weight=balanced ..............\n",
      "[CV]  penalty=l1, loss=perceptron, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l1, loss=perceptron, class_weight=balanced ..............\n",
      "[CV]  penalty=l1, loss=perceptron, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l1, loss=perceptron, class_weight=balanced ..............\n",
      "[CV]  penalty=l1, loss=perceptron, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l1, loss=perceptron, class_weight=balanced ..............\n",
      "[CV]  penalty=l1, loss=perceptron, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l1, loss=perceptron, class_weight=balanced ..............\n",
      "[CV]  penalty=l1, loss=perceptron, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=squared_hinge, class_weight=balanced ...........\n",
      "[CV]  penalty=l2, loss=squared_hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=squared_hinge, class_weight=balanced ...........\n",
      "[CV]  penalty=l2, loss=squared_hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=squared_hinge, class_weight=balanced ...........\n",
      "[CV]  penalty=l2, loss=squared_hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=squared_hinge, class_weight=balanced ...........\n",
      "[CV]  penalty=l2, loss=squared_hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=squared_hinge, class_weight=balanced ...........\n",
      "[CV]  penalty=l2, loss=squared_hinge, class_weight=balanced, total=   0.0s\n",
      "[CV] penalty=l2, loss=perceptron, class_weight=weight ................\n",
      "[CV] . penalty=l2, loss=perceptron, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=perceptron, class_weight=weight ................\n",
      "[CV] . penalty=l2, loss=perceptron, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=perceptron, class_weight=weight ................\n",
      "[CV] . penalty=l2, loss=perceptron, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=perceptron, class_weight=weight ................\n",
      "[CV] . penalty=l2, loss=perceptron, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=perceptron, class_weight=weight ................\n",
      "[CV] . penalty=l2, loss=perceptron, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=hinge, class_weight=weight .....................\n",
      "[CV] ...... penalty=l2, loss=hinge, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=hinge, class_weight=weight .....................\n",
      "[CV] ...... penalty=l2, loss=hinge, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=hinge, class_weight=weight .....................\n",
      "[CV] ...... penalty=l2, loss=hinge, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=hinge, class_weight=weight .....................\n",
      "[CV] ...... penalty=l2, loss=hinge, class_weight=weight, total=   0.0s\n",
      "[CV] penalty=l2, loss=hinge, class_weight=weight .....................\n",
      "[CV] ...... penalty=l2, loss=hinge, class_weight=weight, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=SGDClassifier(), n_jobs=1,\n",
       "                   param_distributions={'class_weight': ['weight', 'balanced'],\n",
       "                                        'loss': ['hinge', 'log',\n",
       "                                                 'modified_huber',\n",
       "                                                 'squared_hinge',\n",
       "                                                 'perceptron'],\n",
       "                                        'penalty': ['l2', 'l1', 'elasticnet']},\n",
       "                   random_state=42, scoring='neg_mean_squared_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd=SGDClassifier()\n",
    "sgd = RandomizedSearchCV(estimator = sgd, param_distributions = random_grid,scoring='neg_mean_squared_error', n_iter = 10, cv = 5, verbose=2, random_state=42, n_jobs = 1)\n",
    "sgd.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c1dc114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "74f90a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.566\n",
      "Precision: 0.4116575591985428\n",
      "ReCall: 0.6706231454005934\n",
      "F1 Score 0.510158013544018\n",
      "__________________________________\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.496\n",
      "Precision: 0.3570127504553734\n",
      "ReCall: 0.5648414985590778\n",
      "F1 Score 0.4375\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "test_pred =  sgd.predict(X_test)\n",
    "train_pred =  sgd.predict(X_test)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1a02d88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ReCall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.866044</td>\n",
       "      <td>0.824926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.863501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.649832</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.859281</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.867069</td>\n",
       "      <td>0.851632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.673947</td>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.640950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.566</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.510158</td>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.411658</td>\n",
       "      <td>0.670623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Cross Validation  F1 Score                        Model  \\\n",
       "0     0.898            0.9920  0.844985                Decision Tree   \n",
       "1     0.912            0.9920  0.868657                Random Forest   \n",
       "2     0.792            0.7785  0.649832           LogisticRegression   \n",
       "3     0.906            0.8020  0.859281                          KNN   \n",
       "4     0.791            0.7555  0.673947                  Naïve Bayes   \n",
       "5     0.566            0.6440  0.510158  Stochastic Gradient Descent   \n",
       "\n",
       "   Precision    ReCall  \n",
       "0   0.866044  0.824926  \n",
       "1   0.873874  0.863501  \n",
       "2   0.750973  0.572700  \n",
       "3   0.867069  0.851632  \n",
       "4   0.710526  0.640950  \n",
       "5   0.411658  0.670623  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " results_df_2 = pd.DataFrame(data=[[\"Stochastic Gradient Descent\", *evaluate(y_test, test_pred) , cross_val( SGDClassifier())]], \n",
    "                          columns=[\"Model\",\"Accuracy\",\"Precision\",\"ReCall\",\"F1 Score\",\"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True,sort = True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2762a1d9",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER FOR GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1c542af0",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Randomized Search CV\n",
    "\n",
    "learning_rate = [1,0.5,0.1,0.01,0.001],\n",
    "max_depth =  [3,5,10,20],\n",
    "n_estimators = [10,50,100,200]\n",
    "loss = ['deviance','exponential']\n",
    "criterion = ['friedman_mse','mse','mae']\n",
    "max_features = ['auto','sqrt','log2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "06002977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': ([1, 0.5, 0.1, 0.01, 0.001],), 'max_depth': ([3, 5, 10, 20],), 'n_estimators': [10, 50, 100, 200], 'loss': ['deviance', 'exponential'], 'criterion': ['friedman_mse', 'mse', 'mae'], 'max_features': ['auto', 'sqrt', 'log2']}\n"
     ]
    }
   ],
   "source": [
    "random_grid = {'learning_rate':learning_rate,\n",
    "               'max_depth':max_depth,\n",
    "               'n_estimators':n_estimators,\n",
    "               'loss':loss,\n",
    "               'criterion':criterion,\n",
    "               'max_features':max_features}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb3533",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6bfa1d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc= GradientBoostingClassifier()\n",
    "gbc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "37bc2450",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "932985c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.857\n",
      "Precision: 0.793939393939394\n",
      "ReCall: 0.7774480712166172\n",
      "F1 Score 0.7856071964017991\n",
      "__________________________________\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.535\n",
      "Precision: 0.3212121212121212\n",
      "ReCall: 0.30547550432276654\n",
      "F1 Score 0.31314623338257014\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "test_pred =  gbc.predict(X_test)\n",
    "train_pred =  gbc.predict(X_test)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ce36e73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ReCall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.866044</td>\n",
       "      <td>0.824926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.863501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.649832</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.859281</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.867069</td>\n",
       "      <td>0.851632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.673947</td>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.640950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.566</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.510158</td>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.411658</td>\n",
       "      <td>0.670623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>0.785607</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.777448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Cross Validation  F1 Score                        Model  \\\n",
       "0     0.898            0.9920  0.844985                Decision Tree   \n",
       "1     0.912            0.9920  0.868657                Random Forest   \n",
       "2     0.792            0.7785  0.649832           LogisticRegression   \n",
       "3     0.906            0.8020  0.859281                          KNN   \n",
       "4     0.791            0.7555  0.673947                  Naïve Bayes   \n",
       "5     0.566            0.6440  0.510158  Stochastic Gradient Descent   \n",
       "6     0.857            0.8805  0.785607   GradientBoostingClassifier   \n",
       "\n",
       "   Precision    ReCall  \n",
       "0   0.866044  0.824926  \n",
       "1   0.873874  0.863501  \n",
       "2   0.750973  0.572700  \n",
       "3   0.867069  0.851632  \n",
       "4   0.710526  0.640950  \n",
       "5   0.411658  0.670623  \n",
       "6   0.793939  0.777448  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"GradientBoostingClassifier\", *evaluate(y_test, test_pred) , cross_val(GradientBoostingClassifier())]], \n",
    "                          columns=[\"Model\",\"Accuracy\",\"Precision\",\"ReCall\",\"F1 Score\",\"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True,sort = True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10462f",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER FOR AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3c996663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized Search CV\n",
    "\n",
    "learning_rate = [1,0.5,0.1,0.01,0.001],\n",
    "n_estimators = [10,50,100,200]\n",
    "algorithm = ['SAMME','SAMME.R']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "71c69e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': ([1, 0.5, 0.1, 0.01, 0.001],), 'n_estimators': [10, 50, 100, 200], 'algorithm': ['SAMME', 'SAMME.R']}\n"
     ]
    }
   ],
   "source": [
    "random_grid = {'learning_rate':learning_rate,\n",
    "               'n_estimators':n_estimators,\n",
    "               'algorithm':algorithm}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2023e7",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "23bd10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c842554e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier()"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "525db794",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "89d1db00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.789\n",
      "Precision: 0.7006369426751592\n",
      "ReCall: 0.6528189910979229\n",
      "F1 Score 0.6758832565284179\n",
      "__________________________________\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.551\n",
      "Precision: 0.3375796178343949\n",
      "ReCall: 0.30547550432276654\n",
      "F1 Score 0.32072617246596064\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "test_pred =  ada.predict(X_test)\n",
    "train_pred =  ada.predict(X_test)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0b2eee33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ReCall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.866044</td>\n",
       "      <td>0.824926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.863501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.649832</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.859281</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.867069</td>\n",
       "      <td>0.851632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.673947</td>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.640950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.566</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.510158</td>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.411658</td>\n",
       "      <td>0.670623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>0.785607</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.777448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.789</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.675883</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.700637</td>\n",
       "      <td>0.652819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Cross Validation  F1 Score                        Model  \\\n",
       "0     0.898            0.9920  0.844985                Decision Tree   \n",
       "1     0.912            0.9920  0.868657                Random Forest   \n",
       "2     0.792            0.7785  0.649832           LogisticRegression   \n",
       "3     0.906            0.8020  0.859281                          KNN   \n",
       "4     0.791            0.7555  0.673947                  Naïve Bayes   \n",
       "5     0.566            0.6440  0.510158  Stochastic Gradient Descent   \n",
       "6     0.857            0.8805  0.785607   GradientBoostingClassifier   \n",
       "7     0.789            0.8005  0.675883           AdaBoostClassifier   \n",
       "\n",
       "   Precision    ReCall  \n",
       "0   0.866044  0.824926  \n",
       "1   0.873874  0.863501  \n",
       "2   0.750973  0.572700  \n",
       "3   0.867069  0.851632  \n",
       "4   0.710526  0.640950  \n",
       "5   0.411658  0.670623  \n",
       "6   0.793939  0.777448  \n",
       "7   0.700637  0.652819  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"AdaBoostClassifier\", *evaluate(y_test, test_pred) , cross_val( AdaBoostClassifier())]], \n",
    "                          columns=[\"Model\",\"Accuracy\",\"Precision\",\"ReCall\",\"F1 Score\",\"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True,sort = True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fb240876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e00cc24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={\n",
    "   \n",
    "    ' learning_rate':[1,0.5,0.1,0.01,0.001],\n",
    "    'max_depth': [3,5,10,20],\n",
    "    'n_estimators':[10,50,100,200]\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc244929",
   "metadata": {},
   "source": [
    "# XTREEM GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d772ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c9d0916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=10 ..................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=10, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=10 ..................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=10, score=0.850, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=10 ..................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=10, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=10 ..................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=10, score=0.775, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=10 ..................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=10, score=0.745, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=50 ..................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=50, score=0.840, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=50 ..................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=1, max_depth=3, n_estimators=50, score=0.905, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=50 ..................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=50, score=0.855, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=50 ..................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=50, score=0.830, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=50 ..................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=50, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=100 .................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=100, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=100 .................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=100 .................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=100, score=0.835, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=100 .................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=100, score=0.855, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=100 .................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=100, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=200 .................\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:28] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=200, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=200 .................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=200, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=200 .................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=200, score=0.845, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=200 .................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=3, n_estimators=200, score=0.890, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=3, n_estimators=200 .................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=1, max_depth=3, n_estimators=200, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=10 ..................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=10, score=0.815, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=10 ..................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=10, score=0.885, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=10 ..................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=10, score=0.820, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=10 ..................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=10, score=0.840, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=10 ..................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=10, score=0.750, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=50 ..................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=50, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=50 ..................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=50 ..................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=50, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=50 ..................\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=50, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=50 ..................\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=50, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=100 .................\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=100, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=100 .................\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=100 .................\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=1, max_depth=5, n_estimators=100, score=0.850, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=100 .................\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=100 .................\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=100, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=200 .................\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=200, score=0.875, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=200 .................\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=200, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=200 .................\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=200, score=0.845, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=200 .................\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=200, score=0.905, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=5, n_estimators=200 .................\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=5, n_estimators=200, score=0.875, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=10 .................\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=10, score=0.865, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=10 .................\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=10, score=0.910, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=10 .................\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=10, score=0.835, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=10 .................\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=10, score=0.895, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=10 .................\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=50 .................\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=1, max_depth=10, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=50 .................\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=50 .................\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=50, score=0.840, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=50 .................\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=50, score=0.925, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=50 .................\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=50, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=100 ................\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=100 ................\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=100 ................\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=100, score=0.840, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=100 ................\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=100, score=0.925, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=100 ................\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=100, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=200 ................\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=200, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=200 ................\n",
      "[15:47:33] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=200, score=0.890, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=200 ................\n",
      "[15:47:33] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=1, max_depth=10, n_estimators=200, score=0.840, total=   0.3s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=200 ................\n",
      "[15:47:33] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=200, score=0.920, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=10, n_estimators=200 ................\n",
      "[15:47:33] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:33] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=10, n_estimators=200, score=0.885, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=10 .................\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=10, score=0.880, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=10 .................\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=10, score=0.910, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=10 .................\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=10, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=10 .................\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=10, score=0.890, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=10 .................\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=10, score=0.855, total=   0.0s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=50 .................\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=50, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=50 .................\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=50, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=50 .................\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=50, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=50 .................\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=50, score=0.910, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=50 .................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=50, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=100 ................\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=100, score=0.870, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=100 ................\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:34] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=100, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=100 ................\n",
      "[15:47:35] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=100, score=0.855, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=100 ................\n",
      "[15:47:35] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=100, score=0.900, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=100 ................\n",
      "[15:47:35] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=100, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=200 ................\n",
      "[15:47:35] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=200, score=0.865, total=   0.3s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=200 ................\n",
      "[15:47:35] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:35] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=200, score=0.900, total=   0.3s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=200 ................\n",
      "[15:47:36] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=200, score=0.845, total=   0.3s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=200 ................\n",
      "[15:47:36] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=200, score=0.895, total=   0.3s\n",
      "[CV]  learning_rate=1, max_depth=20, n_estimators=200 ................\n",
      "[15:47:36] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:36] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=1, max_depth=20, n_estimators=200, score=0.880, total=   0.3s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=10 ................\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=10, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=10 ................\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=10, score=0.850, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=10 ................\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=10, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=10 ................\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=10, score=0.775, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=10 ................\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=10, score=0.745, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50 ................\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=50, score=0.840, total=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50 ................\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=50, score=0.905, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50 ................\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=50, score=0.855, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50 ................\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=50, score=0.830, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=50 ................\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=50, score=0.795, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100 ...............\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=100, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100 ...............\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100 ...............\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=100, score=0.835, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100 ...............\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=100, score=0.855, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=100 ...............\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=100, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200 ...............\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=200, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200 ...............\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=200, score=0.875, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200 ...............\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=200, score=0.845, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200 ...............\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=200, score=0.890, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=3, n_estimators=200 ...............\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=3, n_estimators=200, score=0.885, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=10 ................\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=10, score=0.815, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=10 ................\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=10, score=0.885, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=10 ................\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:38] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=10, score=0.820, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=10 ................\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=10, score=0.840, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=10 ................\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=10, score=0.750, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50 ................\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=50, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50 ................\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50 ................\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=50, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50 ................\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=50, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=50 ................\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=50, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100 ...............\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=100, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100 ...............\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100 ...............\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=100, score=0.850, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100 ...............\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=100 ...............\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:39] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=100, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200 ...............\n",
      "[15:47:40] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=200, score=0.875, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200 ...............\n",
      "[15:47:40] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=200, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200 ...............\n",
      "[15:47:40] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=200, score=0.845, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200 ...............\n",
      "[15:47:40] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=200, score=0.905, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=5, n_estimators=200 ...............\n",
      "[15:47:40] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:40] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=5, n_estimators=200, score=0.875, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=10 ...............\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=10, score=0.865, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=10 ...............\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=10, score=0.910, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=10 ...............\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=10, score=0.835, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=10 ...............\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=10, score=0.895, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=10 ...............\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50 ...............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50 ...............\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50 ...............\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=50, score=0.840, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50 ...............\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=50, score=0.925, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=50 ...............\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=50, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100 ..............\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100 ..............\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:41] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100 ..............\n",
      "[15:47:42] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=100, score=0.840, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100 ..............\n",
      "[15:47:42] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=100, score=0.925, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=100 ..............\n",
      "[15:47:42] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=100, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200 ..............\n",
      "[15:47:42] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=200, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200 ..............\n",
      "[15:47:42] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:42] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=200, score=0.890, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200 ..............\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=200, score=0.840, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200 ..............\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=200, score=0.920, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=10, n_estimators=200 ..............\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=10, n_estimators=200, score=0.885, total=   0.3s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=10 ...............\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=10, score=0.880, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=10 ...............\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=10, score=0.910, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=10 ...............\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=10 ...............\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=10, score=0.890, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=10 ...............\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:43] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=10, score=0.855, total=   0.0s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50 ...............\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=50, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50 ...............\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=50, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50 ...............\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=50, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50 ...............\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=50, score=0.910, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=50 ...............\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=50, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100 ..............\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=100, score=0.870, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100 ..............\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100 ..............\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=100, score=0.855, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100 ..............\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:44] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=100 ..............\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=100, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200 ..............\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=200, score=0.865, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200 ..............\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=200, score=0.900, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200 ..............\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=200, score=0.845, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200 ..............\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=200, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=0.5, max_depth=20, n_estimators=200 ..............\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:45] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.5, max_depth=20, n_estimators=200, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=10 ................\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=10, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=10 ................\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=10, score=0.850, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=10 ................\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=10, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=10 ................\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=10, score=0.775, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=10 ................\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=10, score=0.745, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50 ................\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=50, score=0.840, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50 ................\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=50, score=0.905, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50 ................\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=50, score=0.855, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50 ................\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=50, score=0.830, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=50 ................\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=50, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100 ...............\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=100, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100 ...............\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100 ...............\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=100, score=0.835, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100 ...............\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=100, score=0.855, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=100 ...............\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=100, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200 ...............\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=200, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200 ...............\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:46] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=200, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200 ...............\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=200, score=0.845, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200 ...............\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=200, score=0.890, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=3, n_estimators=200 ...............\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=0.1, max_depth=3, n_estimators=200, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=10 ................\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=10, score=0.815, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=10 ................\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=10, score=0.885, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=10 ................\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=10, score=0.820, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=10 ................\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=10, score=0.840, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=10 ................\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=10, score=0.750, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50 ................\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=50, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50 ................\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50 ................\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=50, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50 ................\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=50, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=50 ................\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=50, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100 ...............\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=100, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100 ...............\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100 ...............\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=100, score=0.850, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100 ...............\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=100 ...............\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=100, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200 ...............\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=200, score=0.875, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200 ...............\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=200, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200 ...............\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:48] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=200, score=0.845, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=200, score=0.905, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=5, n_estimators=200 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=5, n_estimators=200, score=0.875, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=10, score=0.865, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=10, score=0.910, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=10, score=0.835, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=10, score=0.895, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=10 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=50, score=0.840, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=50, score=0.925, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=50 ...............\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:49] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=50, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100 ..............\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100 ..............\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=100, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100 ..............\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=100, score=0.840, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100 ..............\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=100, score=0.925, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=100 ..............\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=100, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200 ..............\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=200, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200 ..............\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:50] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=200, score=0.890, total=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200 ..............\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=200, score=0.840, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200 ..............\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=200, score=0.920, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=10, n_estimators=200 ..............\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=10, n_estimators=200, score=0.885, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=10 ...............\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=10, score=0.880, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=10 ...............\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=10, score=0.910, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=10 ...............\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=10 ...............\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=10, score=0.890, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=10 ...............\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=10, score=0.855, total=   0.0s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50 ...............\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=50, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50 ...............\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:51] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=50, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50 ...............\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=50, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50 ...............\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=50, score=0.910, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=50 ...............\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=50, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:52] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=100, score=0.870, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100 ..............\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100 ..............\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=100, score=0.855, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100 ..............\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=100 ..............\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:52] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=100, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200 ..............\n",
      "[15:47:53] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=200, score=0.865, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200 ..............\n",
      "[15:47:53] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=200, score=0.900, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200 ..............\n",
      "[15:47:53] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=200, score=0.845, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200 ..............\n",
      "[15:47:53] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=200, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=0.1, max_depth=20, n_estimators=200 ..............\n",
      "[15:47:53] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:53] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.1, max_depth=20, n_estimators=200, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=10 ...............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=10, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=10 ...............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=10, score=0.850, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=10 ...............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=10, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=10 ...............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=10, score=0.775, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=10 ...............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=10, score=0.745, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50 ...............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=50, score=0.840, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50 ...............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=50, score=0.905, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50 ...............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=50, score=0.855, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50 ...............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=50, score=0.830, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=50 ...............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=50, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100 ..............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=100, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100 ..............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100 ..............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=100, score=0.835, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100 ..............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=100, score=0.855, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=100 ..............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=100, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200 ..............\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:54] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=200, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200 ..............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=200, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200 ..............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=200, score=0.845, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200 ..............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=200, score=0.890, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=3, n_estimators=200 ..............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=3, n_estimators=200, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=10 ...............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=10, score=0.815, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=10 ...............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=10, score=0.885, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=10 ...............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=10, score=0.820, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=10 ...............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=10, score=0.840, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=10 ...............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=10, score=0.750, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50 ...............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=50, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50 ...............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50 ...............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=50, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50 ...............\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:55] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=50, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=50 ...............\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=50, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100 ..............\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=100, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100 ..............\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100 ..............\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=100, score=0.850, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100 ..............\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=100 ..............\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=100, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200 ..............\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=200, score=0.875, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200 ..............\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:56] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=200, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200 ..............\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=200, score=0.845, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200 ..............\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=200, score=0.905, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=5, n_estimators=200 ..............\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=5, n_estimators=200, score=0.875, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10 ..............\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=10, score=0.865, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10 ..............\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=10, score=0.910, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10 ..............\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=10, score=0.835, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10 ..............\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=10, score=0.895, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=10 ..............\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50 ..............\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50 ..............\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50 ..............\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:57] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=50, score=0.840, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50 ..............\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=50, score=0.925, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=50 ..............\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=50, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100 .............\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100 .............\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=100, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100 .............\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=100, score=0.840, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100 .............\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=100, score=0.925, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=100 .............\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=100, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200 .............\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:58] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=200, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200 .............\n",
      "[15:47:59] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=200, score=0.890, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200 .............\n",
      "[15:47:59] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=200, score=0.840, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200 .............\n",
      "[15:47:59] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=200, score=0.920, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=10, n_estimators=200 .............\n",
      "[15:47:59] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=10, n_estimators=200, score=0.885, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=10 ..............\n",
      "[15:47:59] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=10, score=0.880, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=10 ..............\n",
      "[15:47:59] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:47:59] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=10, score=0.910, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=10 ..............\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=10 ..............\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=10, score=0.890, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=10 ..............\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=10, score=0.855, total=   0.0s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50 ..............\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=50, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50 ..............\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=50, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50 ..............\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=50, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50 ..............\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=50, score=0.910, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=50 ..............\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=50, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100 .............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:00] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=100, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100 .............\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100 .............\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:00] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=100, score=0.855, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100 .............\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=100 .............\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=100, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200 .............\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=200, score=0.865, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200 .............\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=200, score=0.900, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200 .............\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=200, score=0.845, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200 .............\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:01] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=200, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=0.01, max_depth=20, n_estimators=200 .............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.01, max_depth=20, n_estimators=200, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=10 ..............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=10, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=10 ..............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=10, score=0.850, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=10 ..............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=10, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=10 ..............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=10, score=0.775, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=10 ..............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=10, score=0.745, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=50 ..............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=50, score=0.840, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=50 ..............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=50, score=0.905, total=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=50 ..............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=50, score=0.855, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=50 ..............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=50, score=0.830, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=50 ..............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=50, score=0.795, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=100 .............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=100, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=100 .............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=100 .............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=100, score=0.835, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=100 .............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=100, score=0.855, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=100 .............\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:02] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=100, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=200 .............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=200, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=200 .............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=200, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=200 .............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=200, score=0.845, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=200 .............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=200, score=0.890, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=3, n_estimators=200 .............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=0.001, max_depth=3, n_estimators=200, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=10 ..............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=10, score=0.815, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=10 ..............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=10, score=0.885, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=10 ..............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=10, score=0.820, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=10 ..............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=10, score=0.840, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=10 ..............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=10, score=0.750, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=50 ..............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=50, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=50 ..............\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=50 ..............\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=50, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=50 ..............\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=50, score=0.885, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=50 ..............\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=50, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=100 .............\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=100, score=0.875, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=100 .............\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=100 .............\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=100, score=0.850, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=100 .............\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=100 .............\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=100, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=200 .............\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=200, score=0.875, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=200 .............\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:04] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=200, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=200 .............\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=200, score=0.845, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=200 .............\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=200, score=0.905, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=5, n_estimators=200 .............\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=5, n_estimators=200, score=0.875, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=10 .............\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=10, score=0.865, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=10 .............\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=10, score=0.910, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=10 .............\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=10, score=0.835, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=10 .............\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=10, score=0.895, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=10 .............\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=50 .............\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=50 .............\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=50, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=50 .............\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:05] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=50, score=0.840, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=50 .............\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=50, score=0.925, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=50 .............\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=50, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=100 ............\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=100 ............\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=100 ............\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=100, score=0.840, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=100 ............\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=100, score=0.925, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=100 ............\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=100, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=200 ............\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:06] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=200, score=0.880, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=200 ............\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=200, score=0.890, total=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=200 ............\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=200, score=0.840, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=200 ............\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=200, score=0.920, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=10, n_estimators=200 ............\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=10, n_estimators=200, score=0.885, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=10 .............\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=10, score=0.880, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=10 .............\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=10, score=0.910, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=10 .............\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=10, score=0.860, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=10 .............\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=10, score=0.890, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=10 .............\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=10, score=0.855, total=   0.0s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=50 .............\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=50, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=50 .............\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=50, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=50 .............\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=50, score=0.860, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=50 .............\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=50, score=0.910, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=50 .............\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=50, score=0.880, total=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=100 ............\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=100, score=0.870, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=100 ............\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=100, score=0.895, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=100 ............\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=100, score=0.855, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=100 ............\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=100, score=0.900, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=100 ............\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:08] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=100, score=0.880, total=   0.1s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=200 ............\n",
      "[15:48:09] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=200, score=0.865, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=200 ............\n",
      "[15:48:09] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=200, score=0.900, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=200 ............\n",
      "[15:48:09] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=200, score=0.845, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=200 ............\n",
      "[15:48:09] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=200, score=0.895, total=   0.2s\n",
      "[CV]  learning_rate=0.001, max_depth=20, n_estimators=200 ............\n",
      "[15:48:09] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:09] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[CV]   learning_rate=0.001, max_depth=20, n_estimators=200, score=0.880, total=   0.2s\n",
      "[15:48:10] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: {  learning_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[15:48:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 400 out of 400 | elapsed:   41.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, subsample=None,\n",
       "                                     tree_method=None, validate_parameters=None,\n",
       "                                     verbosity=None),\n",
       "             param_grid={' learning_rate': [1, 0.5, 0.1, 0.01, 0.001],\n",
       "                         'max_depth': [3, 5, 10, 20],\n",
       "                         'n_estimators': [10, 50, 100, 200]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb = GridSearchCV(XGBClassifier(objective='binary:logistic'),param_grid, verbose=3)\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6acc19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fc8500bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.918\n",
      "Precision: 0.8761061946902655\n",
      "ReCall: 0.8813056379821959\n",
      "F1 Score 0.8786982248520709\n",
      "__________________________________\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.558\n",
      "Precision: 0.35988200589970504\n",
      "ReCall: 0.3515850144092219\n",
      "F1 Score 0.3556851311953353\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "test_pred =  xgb.predict(X_test)\n",
    "train_pred =  xgb.predict(X_test)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b7e09510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:48:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:48:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:48:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:48:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:48:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:48:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:48:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:48:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:48:11] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ReCall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.866044</td>\n",
       "      <td>0.824926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.863501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.649832</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.859281</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.867069</td>\n",
       "      <td>0.851632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.673947</td>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.640950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.566</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.510158</td>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.411658</td>\n",
       "      <td>0.670623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>0.785607</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.777448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.789</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.675883</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.700637</td>\n",
       "      <td>0.652819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.878698</td>\n",
       "      <td>XTREEM GB</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.881306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Cross Validation  F1 Score                        Model  \\\n",
       "0     0.898            0.9920  0.844985                Decision Tree   \n",
       "1     0.912            0.9920  0.868657                Random Forest   \n",
       "2     0.792            0.7785  0.649832           LogisticRegression   \n",
       "3     0.906            0.8020  0.859281                          KNN   \n",
       "4     0.791            0.7555  0.673947                  Naïve Bayes   \n",
       "5     0.566            0.6440  0.510158  Stochastic Gradient Descent   \n",
       "6     0.857            0.8805  0.785607   GradientBoostingClassifier   \n",
       "7     0.789            0.8005  0.675883           AdaBoostClassifier   \n",
       "8     0.918            0.9920  0.878698                    XTREEM GB   \n",
       "\n",
       "   Precision    ReCall  \n",
       "0   0.866044  0.824926  \n",
       "1   0.873874  0.863501  \n",
       "2   0.750973  0.572700  \n",
       "3   0.867069  0.851632  \n",
       "4   0.710526  0.640950  \n",
       "5   0.411658  0.670623  \n",
       "6   0.793939  0.777448  \n",
       "7   0.700637  0.652819  \n",
       "8   0.876106  0.881306  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"XTREEM GB\", *evaluate(y_test, test_pred) , cross_val( XGBClassifier())]], \n",
    "                          columns=[\"Model\",\"Accuracy\",\"Precision\",\"ReCall\",\"F1 Score\",\"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True,sort = True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "54b3234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = \"classification_XTREEM_GB\"\n",
    "#pickle.dump(xgb,open(filename,\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9920425",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "9e3b12aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "92f5df5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc= svm.SVC()\n",
    "svc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "45e1fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5aedc1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.829\n",
      "Precision: 0.7964285714285714\n",
      "ReCall: 0.6617210682492581\n",
      "F1 Score 0.7228525121555914\n",
      "__________________________________\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "Accuracy: 0.561\n",
      "Precision: 0.3357142857142857\n",
      "ReCall: 0.27089337175792505\n",
      "F1 Score 0.29984051036682613\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "test_pred =  svc.predict(X_test)\n",
    "train_pred =  svc.predict(X_test)\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_test, test_pred)\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(y_train, train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "83b34fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Cross Validation</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision</th>\n",
       "      <th>ReCall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.844985</td>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.866044</td>\n",
       "      <td>0.824926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.868657</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.873874</td>\n",
       "      <td>0.863501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.792</td>\n",
       "      <td>0.7785</td>\n",
       "      <td>0.649832</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>0.572700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.859281</td>\n",
       "      <td>KNN</td>\n",
       "      <td>0.867069</td>\n",
       "      <td>0.851632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.791</td>\n",
       "      <td>0.7555</td>\n",
       "      <td>0.673947</td>\n",
       "      <td>Naïve Bayes</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.640950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.566</td>\n",
       "      <td>0.6440</td>\n",
       "      <td>0.510158</td>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.411658</td>\n",
       "      <td>0.670623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.857</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>0.785607</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.793939</td>\n",
       "      <td>0.777448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.789</td>\n",
       "      <td>0.8005</td>\n",
       "      <td>0.675883</td>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.700637</td>\n",
       "      <td>0.652819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.918</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>0.878698</td>\n",
       "      <td>XTREEM GB</td>\n",
       "      <td>0.876106</td>\n",
       "      <td>0.881306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.829</td>\n",
       "      <td>0.7685</td>\n",
       "      <td>0.722853</td>\n",
       "      <td>SUPPORT VECTOR CLASSIFIER</td>\n",
       "      <td>0.796429</td>\n",
       "      <td>0.661721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Cross Validation  F1 Score                        Model  \\\n",
       "0     0.898            0.9920  0.844985                Decision Tree   \n",
       "1     0.912            0.9920  0.868657                Random Forest   \n",
       "2     0.792            0.7785  0.649832           LogisticRegression   \n",
       "3     0.906            0.8020  0.859281                          KNN   \n",
       "4     0.791            0.7555  0.673947                  Naïve Bayes   \n",
       "5     0.566            0.6440  0.510158  Stochastic Gradient Descent   \n",
       "6     0.857            0.8805  0.785607   GradientBoostingClassifier   \n",
       "7     0.789            0.8005  0.675883           AdaBoostClassifier   \n",
       "8     0.918            0.9920  0.878698                    XTREEM GB   \n",
       "9     0.829            0.7685  0.722853    SUPPORT VECTOR CLASSIFIER   \n",
       "\n",
       "   Precision    ReCall  \n",
       "0   0.866044  0.824926  \n",
       "1   0.873874  0.863501  \n",
       "2   0.750973  0.572700  \n",
       "3   0.867069  0.851632  \n",
       "4   0.710526  0.640950  \n",
       "5   0.411658  0.670623  \n",
       "6   0.793939  0.777448  \n",
       "7   0.700637  0.652819  \n",
       "8   0.876106  0.881306  \n",
       "9   0.796429  0.661721  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_2 = pd.DataFrame(data=[[\"SUPPORT VECTOR CLASSIFIER\", *evaluate(y_test, test_pred) , cross_val(svm.SVC())]], \n",
    "                          columns=[\"Model\",\"Accuracy\",\"Precision\",\"ReCall\",\"F1 Score\",\"Cross Validation\"])\n",
    "results_df = results_df.append(results_df_2, ignore_index=True,sort = True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be70932b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
